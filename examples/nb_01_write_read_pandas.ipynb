{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Writing and Reading Time Series with TimeDB SDK\n",
        "\n",
        "This notebook demonstrates:\n",
        "1. Writing time series data without specifying series_id (auto-generated)\n",
        "2. Reading data back and plotting with series_id in legend\n",
        "3. Writing multiple time series with the same series_id (updates)\n",
        "4. Reading back to see consolidated time series\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import timedb as td\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Two Different Time Series (Different Series IDs)\n",
        "\n",
        "First, let's create the schema and write two different time series without specifying series_id.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete database schema\n",
        "td.delete()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating database schema...\n",
            "✓ Schema created successfully\n"
          ]
        }
      ],
      "source": [
        "# Create database schema\n",
        "td.create()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data values inserted successfully.\n",
            "InsertResult(run_id=UUID('5322a4b0-32c1-42ae-8f17-8ff62b989437'), workflow_id='sdk-workflow', series_ids={'value': UUID('42a7a84f-72fa-4d8b-81ff-054cc8b98ee6')}, tenant_id=UUID('00000000-0000-0000-0000-000000000000'))\n",
            "✓ Inserted first time series with series_id: {'value': UUID('42a7a84f-72fa-4d8b-81ff-054cc8b98ee6')}\n",
            "  Time range: 2025-01-01 00:00:00+00:00 to 2025-01-01 23:00:00+00:00\n"
          ]
        }
      ],
      "source": [
        "# Create first time series: Temperature data (first 24 hours: 0-23)\n",
        "base_time = datetime(2025, 1, 1, 0, 0, tzinfo=timezone.utc)\n",
        "dates1 = [base_time + timedelta(hours=i) for i in range(24)]\n",
        "df1 = pd.DataFrame({\n",
        "    'valid_time': dates1,\n",
        "    'value': [20.0 + i * 0.3 for i in range(24)]  # Temperature rising\n",
        "})\n",
        "\n",
        "# Insert first time series (series_id will be auto-generated)\n",
        "result1 = td.insert_run(df=df1)\n",
        "print(result1)\n",
        "print(f\"✓ Inserted first time series with series_id: {result1.series_ids}\")\n",
        "print(f\"  Time range: {dates1[0]} to {dates1[-1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data values inserted successfully.\n",
            "✓ Inserted second time series with series_id: {'value': UUID('ed35bed3-477a-452c-b213-7c8c230ac86b')}\n",
            "  Time range: 2025-01-02 00:00:00+00:00 to 2025-01-02 23:00:00+00:00\n"
          ]
        }
      ],
      "source": [
        "# Create second time series: Humidity data (next 24 hours: 24-47, following the first)\n",
        "dates2 = [base_time + timedelta(hours=i) for i in range(24, 48)]  # Hours 24-47\n",
        "df2 = pd.DataFrame({\n",
        "    'valid_time': dates2,\n",
        "    'value': [30.0 - (i-24) * 0.5 for i in range(24, 48)]  # Humidity decreasing\n",
        "})\n",
        "\n",
        "# Insert second time series (series_id will be auto-generated, different from first)\n",
        "result2 = td.insert_run(df=df2)\n",
        "print(f\"✓ Inserted second time series with series_id: {result2.series_ids}\")\n",
        "print(f\"  Time range: {dates2[0]} to {dates2[-1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Read 48 rows\n",
            "\n",
            "DataFrame shape: (48, 2)\n",
            "Index names: ['valid_time']\n",
            "Column level names: ['series_key']\n",
            "\n",
            "Series keys in columns: Index(['value'], dtype='object', name='series_key')\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'Requested level (series_ids) does not match index name (valid_time)'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumn level names: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_read.columns.names\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSeries keys in columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_read.columns.get_level_values(\u001b[33m'\u001b[39m\u001b[33mseries_key\u001b[39m\u001b[33m'\u001b[39m).unique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSeries IDs in data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdf_read\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_level_values\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mseries_ids\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m.unique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFirst few rows:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_read.head(\u001b[32m10\u001b[39m))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/src/rebase-energy/myfork/timedb/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py:2109\u001b[39m, in \u001b[36mIndex._get_level_values\u001b[39m\u001b[34m(self, level)\u001b[39m\n\u001b[32m   2073\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_level_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, level) -> Index:\n\u001b[32m   2074\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2075\u001b[39m \u001b[33;03m    Return an Index of values for requested level.\u001b[39;00m\n\u001b[32m   2076\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2107\u001b[39m \u001b[33;03m    Index(['a', 'b', 'c'], dtype='object')\u001b[39;00m\n\u001b[32m   2108\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2109\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_index_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2110\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/src/rebase-energy/myfork/timedb/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py:2019\u001b[39m, in \u001b[36mIndex._validate_index_level\u001b[39m\u001b[34m(self, level)\u001b[39m\n\u001b[32m   2015\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[32m   2016\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mToo many levels: Index has only 1 level, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2017\u001b[39m         )\n\u001b[32m   2018\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m level != \u001b[38;5;28mself\u001b[39m.name:\n\u001b[32m-> \u001b[39m\u001b[32m2019\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m   2020\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRequested level (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) does not match index name (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2021\u001b[39m     )\n",
            "\u001b[31mKeyError\u001b[39m: 'Requested level (series_ids) does not match index name (valid_time)'"
          ]
        }
      ],
      "source": [
        "# Read back all time series\n",
        "df_read = td.read()\n",
        "# df_read.info()\n",
        "# print(df_read.columns)\n",
        "# print(df_read.columns.names)\n",
        "# print(df_read.index)\n",
        "print(f\"✓ Read {len(df_read)} rows\")\n",
        "print(f\"\\nDataFrame shape: {df_read.shape}\")\n",
        "\n",
        "\n",
        "print(f\"Index names: {df_read.index.names}\")\n",
        "print(f\"Column level names: {df_read.columns.names}\")\n",
        "print(f\"\\nSeries keys in columns: {df_read.columns.get_level_values('series_key').unique()}\")\n",
        "\n",
        "print(f\"\\nSeries IDs in data: {df_read.index.get_level_values('series_ids').unique()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df_read.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for plotting\n",
        "# Reset index to get series_id as a column\n",
        "df_plot = df_read.reset_index()\n",
        "\n",
        "# Handle potential duplicates: if same (valid_time, series_id, value_key) exists, take the first\n",
        "# (This shouldn't happen with DISTINCT ON, but just in case)\n",
        "df_plot = df_plot.drop_duplicates(subset=['valid_time', 'series_id', 'value_key'])\n",
        "\n",
        "# Pivot to have series_id as columns for plotting\n",
        "df_pivot = df_plot.pivot(index='valid_time', columns='series_id', values='value')\n",
        "\n",
        "# Plot both time series\n",
        "plt.figure(figsize=(12, 6))\n",
        "for series_id in df_pivot.columns:\n",
        "    plt.plot(df_pivot.index, df_pivot[series_id], marker='o', label=f'series_id: {series_id}')\n",
        "\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Two Different Time Series (Different Series IDs)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n✓ Plotted {len(df_pivot.columns)} different time series (different series_ids)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Same Series ID (Consolidated Time Series)\n",
        "\n",
        "Now let's delete the schema and repeat, but this time we'll use the same series_id for both writes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete schema to start fresh\n",
        "td.delete()\n",
        "\n",
        "# Create schema again\n",
        "td.create()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a shared series_id\n",
        "import uuid\n",
        "shared_series_id = uuid.uuid4()\n",
        "print(f\"Using shared series_id: {shared_series_id}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insert first time series with explicit series_id\n",
        "result1 = td.insert_run(df=df1, series_id=shared_series_id)\n",
        "print(f\"✓ Inserted first time series with series_id: {result1.series_id}\")\n",
        "print(f\"  Time range: {dates1[0]} to {dates1[-1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Insert second time series with the SAME series_id\n",
        "result2 = td.insert_run(df=df2, series_id=shared_series_id)\n",
        "print(f\"✓ Inserted second time series with series_id: {result2.series_id}\")\n",
        "print(f\"  Time range: {dates2[0]} to {dates2[-1]}\")\n",
        "print(f\"  (Same series_id as first: {result1.series_id == result2.series_id})\")\n",
        "print(f\"  Note: The two time series will be stitched together since they have consecutive time ranges!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read back all time series\n",
        "df_read = td.read()\n",
        "print(f\"✓ Read {len(df_read)} rows\")\n",
        "print(f\"\\nDataFrame shape: {df_read.shape}\")\n",
        "print(f\"\\nSeries IDs in data: {df_read.index.get_level_values('series_id').unique()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df_read.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for plotting\n",
        "# Reset index to get series_id as a column\n",
        "df_plot = df_read.reset_index()\n",
        "\n",
        "# Handle potential duplicates: if same (valid_time, series_id, value_key) exists, take the first\n",
        "# (This shouldn't happen with DISTINCT ON, but just in case)\n",
        "#f_plot = df_plot.drop_duplicates(subset=['valid_time', 'series_id', 'value_key'])\n",
        "\n",
        "# Pivot to have series_id as columns for plotting\n",
        "df_pivot = df_plot.pivot(index='valid_time', columns='series_id', values='value')\n",
        "\n",
        "# Plot the time series\n",
        "plt.figure(figsize=(12, 6))\n",
        "for series_id in df_pivot.columns:\n",
        "    plt.plot(df_pivot.index, df_pivot[series_id], marker='o', label=f'Series {series_id}')\n",
        "\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Time Series with Same Series ID (Consolidated)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n✓ Plotted {len(df_pivot.columns)} time series\")\n",
        "print(f\"  Note: Both writes used the same series_id, so we see one consolidated time series\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "timedb",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
